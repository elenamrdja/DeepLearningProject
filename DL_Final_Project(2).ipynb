{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:31.342094Z",
     "iopub.status.busy": "2022-05-02T03:00:31.341518Z",
     "iopub.status.idle": "2022-05-02T03:00:31.352242Z",
     "shell.execute_reply": "2022-05-02T03:00:31.351535Z",
     "shell.execute_reply.started": "2022-05-02T03:00:31.342057Z"
    },
    "id": "JVXLM4-fZ_9P",
    "outputId": "f3326fc0-ad70-4476-ddad-68452cdd306d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: transformers in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (4.18.0)\n",
      "Requirement already satisfied: requests in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: sacremoses in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: filelock in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: click in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: torch in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages (from torch) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kPgh21ypaMrA"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input,BatchNormalization,Dropout,Embedding,Flatten,SimpleRNN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:31.355128Z",
     "iopub.status.busy": "2022-05-02T03:00:31.354545Z",
     "iopub.status.idle": "2022-05-02T03:00:32.051687Z",
     "shell.execute_reply": "2022-05-02T03:00:32.050928Z",
     "shell.execute_reply.started": "2022-05-02T03:00:31.355045Z"
    },
    "id": "aEKdf2DFZ_9W"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('our_data.csv', delimiter = ';', lineterminator = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:32.056314Z",
     "iopub.status.busy": "2022-05-02T03:00:32.0561Z",
     "iopub.status.idle": "2022-05-02T03:00:32.060456Z",
     "shell.execute_reply": "2022-05-02T03:00:32.059458Z",
     "shell.execute_reply.started": "2022-05-02T03:00:32.05629Z"
    },
    "id": "YSi7WbFsZ_9X"
   },
   "outputs": [],
   "source": [
    "# dropping last row\n",
    "data = data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xFfb13imbUvE",
    "outputId": "aa76f31a-16c6-4bf8-852d-81647a67bc7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>desire</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>confusion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI am super happy for you!!</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nOh very very good</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nThank youuu!!!</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHahahahahah</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nLook I hesitated between Maksime and Maxime ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>\\nNeither do i</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>\\nIn person</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>\\nA friend of mine told that we should have en...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>\\nOsnakjlfafv</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>\\nIcannot</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>596 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text example_very_unclear  \\\n",
       "0                         \\nI am super happy for you!!                False   \n",
       "1                                  \\nOh very very good                False   \n",
       "2                                     \\nThank youuu!!!                False   \n",
       "3                                        \\nHahahahahah                False   \n",
       "4    \\nLook I hesitated between Maksime and Maxime ...                False   \n",
       "..                                                 ...                  ...   \n",
       "591                                     \\nNeither do i                 True   \n",
       "592                                       \\nIn person                  True   \n",
       "593  \\nA friend of mine told that we should have en...                 True   \n",
       "594                                      \\nOsnakjlfafv                 True   \n",
       "595                                          \\nIcannot                 True   \n",
       "\n",
       "     joy  anger  desire  curiosity  disappointment  confusion  label  \n",
       "0    1.0    0.0     0.0        0.0             0.0        0.0    1.0  \n",
       "1    1.0    0.0     0.0        0.0             0.0        0.0    1.0  \n",
       "2    1.0    0.0     0.0        0.0             0.0        0.0    1.0  \n",
       "3    1.0    0.0     0.0        0.0             0.0        0.0    1.0  \n",
       "4    1.0    0.0     0.0        0.0             0.0        0.0    1.0  \n",
       "..   ...    ...     ...        ...             ...        ...    ...  \n",
       "591  0.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "592  0.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "593  0.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "594  0.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "595  0.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "\n",
       "[596 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:32.071902Z",
     "iopub.status.busy": "2022-05-02T03:00:32.071347Z",
     "iopub.status.idle": "2022-05-02T03:00:32.078273Z",
     "shell.execute_reply": "2022-05-02T03:00:32.077575Z",
     "shell.execute_reply.started": "2022-05-02T03:00:32.071866Z"
    },
    "id": "PIydBAeXZ_9Z"
   },
   "outputs": [],
   "source": [
    "# creating mapping of emotion to number\n",
    "dct = {0 : 'joy', 1 : 'anger', 2 : 'desire', 3:'curiosity', 4 : 'disappointment', 5 : 'confusion'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:35.238368Z",
     "iopub.status.busy": "2022-05-02T03:00:35.237423Z",
     "iopub.status.idle": "2022-05-02T03:00:35.266415Z",
     "shell.execute_reply": "2022-05-02T03:00:35.26568Z",
     "shell.execute_reply.started": "2022-05-02T03:00:35.23833Z"
    },
    "id": "Q36RsKdSZ_9i"
   },
   "outputs": [],
   "source": [
    "# fetching only raws that is clear\n",
    "data = data[data['example_very_unclear'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "z0TvosoCb1Jx",
    "outputId": "ef3f8742-2d3f-4235-b73c-895e22864b9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423825/2881916659.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'] - 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>desire</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>confusion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI am super happy for you!!</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nOh very very good</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nThank youuu!!!</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nHahahahahah</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nLook I hesitated between Maksime and Maxime ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text example_very_unclear  \\\n",
       "0                       \\nI am super happy for you!!                False   \n",
       "1                                \\nOh very very good                False   \n",
       "2                                   \\nThank youuu!!!                False   \n",
       "3                                      \\nHahahahahah                False   \n",
       "4  \\nLook I hesitated between Maksime and Maxime ...                False   \n",
       "\n",
       "   joy  anger  desire  curiosity  disappointment  confusion  label  \n",
       "0  1.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "1  1.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "2  1.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "3  1.0    0.0     0.0        0.0             0.0        0.0    0.0  \n",
       "4  1.0    0.0     0.0        0.0             0.0        0.0    0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "data['label'] = data['label'] - 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:35.268242Z",
     "iopub.status.busy": "2022-05-02T03:00:35.267931Z",
     "iopub.status.idle": "2022-05-02T03:00:35.272439Z",
     "shell.execute_reply": "2022-05-02T03:00:35.271498Z",
     "shell.execute_reply.started": "2022-05-02T03:00:35.268189Z"
    },
    "id": "SWIUllcAZ_9j"
   },
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "  data = data.sample(frac=1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2022-05-02T03:00:35.274485Z",
     "iopub.status.busy": "2022-05-02T03:00:35.273997Z",
     "iopub.status.idle": "2022-05-02T03:00:35.298102Z",
     "shell.execute_reply": "2022-05-02T03:00:35.297159Z",
     "shell.execute_reply.started": "2022-05-02T03:00:35.274449Z"
    },
    "id": "YF7ragOSZ_9j",
    "outputId": "fe062ea3-f594-4536-8cda-bb406f44d756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 3, 0, 1, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U4hXpm8Z_9k"
   },
   "source": [
    "# **Using Bert Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y075WB9jZ_9o"
   },
   "source": [
    "# converting one hot vector of emotion to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:01:05.405063Z",
     "iopub.status.busy": "2022-05-02T03:01:05.404849Z",
     "iopub.status.idle": "2022-05-02T03:01:05.413042Z",
     "shell.execute_reply": "2022-05-02T03:01:05.412169Z",
     "shell.execute_reply.started": "2022-05-02T03:01:05.405036Z"
    },
    "id": "-IQRnVTZZ_9p"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm, trange,tnrange,tqdm_notebook\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "# % matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:01:05.417261Z",
     "iopub.status.busy": "2022-05-02T03:01:05.414343Z",
     "iopub.status.idle": "2022-05-02T03:01:05.425373Z",
     "shell.execute_reply": "2022-05-02T03:01:05.424631Z",
     "shell.execute_reply.started": "2022-05-02T03:01:05.417232Z"
    },
    "id": "qDpeJHkeZ_9q"
   },
   "outputs": [],
   "source": [
    "# identify and specify the GPU as the device, later in training loop we will load data into device\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "SEED = 19\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:01:05.42719Z",
     "iopub.status.busy": "2022-05-02T03:01:05.426687Z",
     "iopub.status.idle": "2022-05-02T03:01:05.433811Z",
     "shell.execute_reply": "2022-05-02T03:01:05.433141Z",
     "shell.execute_reply.started": "2022-05-02T03:01:05.427081Z"
    },
    "id": "rJNQsPhpZ_9r"
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "s0pD9xQHgWbn"
   },
   "outputs": [],
   "source": [
    "data.drop(['example_very_unclear'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "__AiTn00jFiP",
    "outputId": "88028c5f-9018-4607-e46f-7b1563dba405"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>desire</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>confusion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>\\nis it just me or MAA105 final exam is 3h long?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>\\n\"Don't hesitate to send me pictures :)\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>\\n\"are u here on Friday?\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>\\n\"For you want to go to the shop together, ma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>\\n\"Oh I see... it's a bit confusing though\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>\\ncalm down, youre not the only one cleaning t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>\\n\"Where u at?\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>\\n\"Ahh I like to watch you play  That's so nic...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>\\n\"both options are bad\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>\\n\"You really look amazing in it\\n\"</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  joy  anger  desire  \\\n",
       "554   \\nis it just me or MAA105 final exam is 3h long?  0.0    0.0     0.0   \n",
       "188        \\n\"Don't hesitate to send me pictures :)\\n\"  0.0    0.0     1.0   \n",
       "327                        \\n\"are u here on Friday?\\n\"  0.0    0.0     0.0   \n",
       "238  \\n\"For you want to go to the shop together, ma...  0.0    0.0     1.0   \n",
       "483      \\n\"Oh I see... it's a bit confusing though\\n\"  0.0    0.0     0.0   \n",
       "..                                                 ...  ...    ...     ...   \n",
       "116  \\ncalm down, youre not the only one cleaning t...  0.0    1.0     0.0   \n",
       "511                                  \\n\"Where u at?\\n\"  0.0    0.0     0.0   \n",
       "198  \\n\"Ahh I like to watch you play  That's so nic...  0.0    0.0     1.0   \n",
       "455                         \\n\"both options are bad\\n\"  0.0    0.0     0.0   \n",
       "292                \\n\"You really look amazing in it\\n\"  0.0    0.0     1.0   \n",
       "\n",
       "     curiosity  disappointment  confusion  label  \n",
       "554        0.0             0.0        1.0    5.0  \n",
       "188        0.0             0.0        0.0    2.0  \n",
       "327        1.0             0.0        0.0    3.0  \n",
       "238        0.0             0.0        0.0    2.0  \n",
       "483        0.0             0.0        1.0    5.0  \n",
       "..         ...             ...        ...    ...  \n",
       "116        0.0             0.0        0.0    1.0  \n",
       "511        0.0             0.0        1.0    5.0  \n",
       "198        0.0             0.0        0.0    2.0  \n",
       "455        0.0             1.0        0.0    4.0  \n",
       "292        0.0             0.0        0.0    2.0  \n",
       "\n",
       "[558 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-05-02T03:01:32.667101Z",
     "iopub.status.busy": "2022-05-02T03:01:32.666831Z",
     "iopub.status.idle": "2022-05-02T03:02:40.442926Z",
     "shell.execute_reply": "2022-05-02T03:02:40.442138Z",
     "shell.execute_reply.started": "2022-05-02T03:01:32.667071Z"
    },
    "id": "xpjApAR9Z_9r",
    "outputId": "bc3d0019-7abe-40c2-a9b1-872a5c56dd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of data based on labels:  2.0    113\n",
      "0.0    103\n",
      "3.0    101\n",
      "4.0     80\n",
      "1.0     79\n",
      "5.0     78\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sentence before tokenization:  \n",
      "\"are u here on Friday?\n",
      "\"\n",
      "Encoded Input from dataset:  [101, 1000, 2024, 1057, 2182, 2006, 5958, 1029, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## create label and sentence list\n",
    "sentences = data.text.values\n",
    "\n",
    "#check distribution of data based on labels\n",
    "print(\"Distribution of data based on labels: \",data.label.value_counts())\n",
    "\n",
    "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room for more anyway. \n",
    "# In the original paper, the authors used a length of 512.\n",
    "MAX_LEN = 256\n",
    "\n",
    "## Import BERT tokenizer, that is used to convert our text into tokens that corresponds to BERT library\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "input_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\n",
    "labels = data.label.values\n",
    "\n",
    "print(\"Actual sentence before tokenization: \",sentences[2])\n",
    "print(\"Encoded Input from dataset: \",input_ids[2])\n",
    "\n",
    "## Create attention mask\n",
    "attention_masks = []\n",
    "## Create a mask of 1 for all input tokens and 0 for all padding tokens\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "print(attention_masks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:02:40.445097Z",
     "iopub.status.busy": "2022-05-02T03:02:40.444655Z",
     "iopub.status.idle": "2022-05-02T03:02:40.536223Z",
     "shell.execute_reply": "2022-05-02T03:02:40.535489Z",
     "shell.execute_reply.started": "2022-05-02T03:02:40.445059Z"
    },
    "id": "7Oy4OMGGZ_9s"
   },
   "outputs": [],
   "source": [
    "train_inputs,validation_inputs,train_labels,validation_labels = train_test_split(input_ids,labels,random_state=41,test_size=0.1)\n",
    "train_masks,validation_masks,_,_ = train_test_split(attention_masks,input_ids,random_state=41,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMe7nifHgylF",
    "outputId": "621ef5bc-73c8-4499-c3c1-f3468d08f56b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423825/2787345946.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = [int(x) for x in data['label']]\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data['label'] = [int(x) for x in data['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "BBAXhV77hPcZ",
    "outputId": "93a421da-8bae-4c0b-fe0c-330ea09050e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.isna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-02T03:02:40.53766Z",
     "iopub.status.busy": "2022-05-02T03:02:40.537413Z",
     "iopub.status.idle": "2022-05-02T03:02:45.640526Z",
     "shell.execute_reply": "2022-05-02T03:02:45.639641Z",
     "shell.execute_reply.started": "2022-05-02T03:02:40.537626Z"
    },
    "id": "QYbbviJ8Z_9u"
   },
   "outputs": [],
   "source": [
    "# convert all our data into torch tensors, required data type for my model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 192\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-05-02T03:02:45.642719Z",
     "iopub.status.busy": "2022-05-02T03:02:45.642209Z",
     "iopub.status.idle": "2022-05-02T03:03:08.441699Z",
     "shell.execute_reply": "2022-05-02T03:03:08.43996Z",
     "shell.execute_reply.started": "2022-05-02T03:02:45.64268Z"
    },
    "id": "G1GSD5sXZ_9w",
    "outputId": "8dfb68b4-9793-4a8c-df0f-fc1e3548f748"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mert/miniconda3/envs/olymposc/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6).to(device)\n",
    "\n",
    "# Parameters:\n",
    "lr = 2e-5\n",
    "adam_epsilon = 1e-8\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "num_warmup_steps = 0\n",
    "num_training_steps = len(train_dataloader)*epochs\n",
    "\n",
    "### In Transformers, optimizer and schedules are splitted and instantiated like this:\n",
    "optimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536,
     "referenced_widgets": [
      "9d33fafff43346a2bfbccc0c50aff720",
      "f8afbb92ca014f219f18f07268c2ab5e",
      "01ea05b47b924ca2bd7c91d745cb382f",
      "c489d97b48764cd486abab014eefa0dc",
      "96584148f53b4bb98eb268128878a12b",
      "106e043e851148abb296604a404cc16b",
      "c3bee43324794fb49183d136ac03eeb7",
      "cb0c9a6f794247509852cdbff4e793fd",
      "6004ecc918184bcab75e16e003c94326",
      "f9a27803815a4762b961327e101b6fef",
      "99b5a761332242fdb31f325205a283c3"
     ]
    },
    "execution": {
     "iopub.execute_input": "2022-05-02T03:03:08.443531Z",
     "iopub.status.busy": "2022-05-02T03:03:08.44328Z"
    },
    "id": "A4gGDrHkZ_9x",
    "outputId": "8d47e49a-3921-4f35-af13-9a4c8d982204"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423825/878521272.py:9: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for _ in tnrange(1,epochs+1,desc='Epoch'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9572d34371324f60983243d7ec599321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 \n",
      "tensor([1., 0., 4., 4., 1., 3., 0., 3., 4., 0., 1., 2., 4., 3., 2., 1., 5., 5.,\n",
      "        2., 0., 4., 2., 2., 4., 2., 3., 3., 2., 0., 1., 1., 0., 4., 0., 1., 5.,\n",
      "        5., 2., 2., 5., 2., 3., 4., 3., 0., 0., 1., 4., 2., 2., 0., 0., 4., 4.,\n",
      "        4., 5., 5., 3., 2., 3., 5., 1., 1., 0., 1., 3., 1., 3., 1., 1., 2., 0.,\n",
      "        1., 1., 0., 4., 3., 2., 3., 3., 4., 2., 3., 0., 0., 4., 1., 4., 3., 0.,\n",
      "        2., 2., 0., 2., 3., 0., 1., 0., 4., 0., 2., 4., 0., 3., 1., 2., 2., 5.,\n",
      "        1., 5., 5., 3., 3., 3., 1., 1., 5., 4., 4., 5., 3., 2., 4., 5., 3., 2.,\n",
      "        3., 1., 5., 0., 0., 5., 5., 2., 2., 0., 5., 5., 0., 0., 0., 0., 1., 0.,\n",
      "        5., 3., 2., 0., 1., 2., 0., 3., 4., 0., 4., 3., 1., 4., 1., 5., 3., 2.,\n",
      "        0., 4., 2., 1., 0., 4., nan, 1., 0., 3., 3., 3., 5., 2., 3., 5., 2., 0.,\n",
      "        4., 3., 0., 1., 2., 5., 3., 0., 1., 2., 2., 5.], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m b_input_ids, b_input_mask, b_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print('Ids', b_input_ids.shape)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#print('Ilon mask', b_input_mask.shape)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#print('Labels', b_labels.to(torch.int64))\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m b_labels \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#print(b_labels.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#b_labels = torch.nn.functional.one_hot(b_labels)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(b_input_ids, token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39mb_input_mask, labels\u001b[38;5;241m=\u001b[39mb_labels)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be non-negative."
     ]
    }
   ],
   "source": [
    "## Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "learning_rate = []\n",
    "\n",
    "# Gradients gets accumulated by default\n",
    "model.zero_grad()\n",
    "\n",
    "# tnrange is a tqdm wrapper around the normal python range\n",
    "for _ in tnrange(1,epochs+1,desc='Epoch'):\n",
    "  print( F\" Epoch {_} \")\n",
    "  # Calculate total loss for this epoch\n",
    "  batch_loss = 0\n",
    "\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "    \n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    print(b_labels)\n",
    "    b_labels.dropna\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_labels = F.one_hot(b_labels.to(torch.int64), num_classes=6)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    loss = outputs[0]\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip the norm of the gradients to 1.0\n",
    "    # Gradient clipping is not in AdamW anymore\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update learning rate schedule\n",
    "    scheduler.step()\n",
    "\n",
    "    # Clear the previous accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Update tracking variables\n",
    "    batch_loss += loss.item()\n",
    "\n",
    "  # Calculate the average loss over the training data.\n",
    "  avg_train_loss = batch_loss / len(train_dataloader)\n",
    "\n",
    "  #store the current learning rate\n",
    "  for param_group in optimizer.param_groups:\n",
    "    print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n",
    "    learning_rate.append(param_group['lr'])\n",
    "    \n",
    "  train_loss_set.append(avg_train_loss)\n",
    "  print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n",
    "    \n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  eval_accuracy,eval_mcc_accuracy,nb_eval_steps = 0, 0, 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits[0].to('cpu').numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat = label_ids.flatten()\n",
    "    \n",
    "    df_metrics=pd.DataFrame({'Epoch':epochs,'Actual_class':labels_flat,'Predicted_class':pred_flat})\n",
    "    \n",
    "    tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n",
    "    tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n",
    "    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    eval_mcc_accuracy += tmp_eval_mcc_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n",
    "  print(F'\\n\\tValidation MCC Accuracy: {eval_mcc_accuracy/nb_eval_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ML (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01ea05b47b924ca2bd7c91d745cb382f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb0c9a6f794247509852cdbff4e793fd",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6004ecc918184bcab75e16e003c94326",
      "value": 0
     }
    },
    "106e043e851148abb296604a404cc16b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6004ecc918184bcab75e16e003c94326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "96584148f53b4bb98eb268128878a12b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99b5a761332242fdb31f325205a283c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d33fafff43346a2bfbccc0c50aff720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f8afbb92ca014f219f18f07268c2ab5e",
       "IPY_MODEL_01ea05b47b924ca2bd7c91d745cb382f",
       "IPY_MODEL_c489d97b48764cd486abab014eefa0dc"
      ],
      "layout": "IPY_MODEL_96584148f53b4bb98eb268128878a12b"
     }
    },
    "c3bee43324794fb49183d136ac03eeb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c489d97b48764cd486abab014eefa0dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9a27803815a4762b961327e101b6fef",
      "placeholder": "​",
      "style": "IPY_MODEL_99b5a761332242fdb31f325205a283c3",
      "value": " 0/3 [00:00&lt;?, ?it/s]"
     }
    },
    "cb0c9a6f794247509852cdbff4e793fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8afbb92ca014f219f18f07268c2ab5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_106e043e851148abb296604a404cc16b",
      "placeholder": "​",
      "style": "IPY_MODEL_c3bee43324794fb49183d136ac03eeb7",
      "value": "Epoch:   0%"
     }
    },
    "f9a27803815a4762b961327e101b6fef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
